require 'torch'
require 'cutorch'
require 'cunn'
require 'optim'
require 'xlua'

require 'hdf5'

require 'StackShift'

-- Implementing: https://gist.github.com/shelhamer/80667189b218ad570e82#file-readme-md

-- Splits strings. From: http://stackoverflow.com/questions/1426954/split-string-in-lua
function string_split(inputstr, sep)
        if sep == nil then
                sep = "%s"
        end
        local t={} ; i=1
        for str in string.gmatch(inputstr, "([^"..sep.."]+)") do
                t[i] = str
                i = i + 1
        end
        return t
end

-- Get the file to use, if there is none use a default
file_name = arg[1] or "default.txt"
print("Using configuration from file: " .. file_name)

-- Open the config file
config_file = io.open(file_name, 'rb')

-- This table stores the parsed arguments
config_table = {}
-- WARNING: assumes all required values are present
-- Required keys
-- save_name
-- data_name
-- test_name
--
-- Optional
-- gpu_id
-- output_level

-- Go through each line in the file
for line in config_file:lines() do

	-- Split the words in the line
	local words = string_split(line)

	-- The first word is the key word
	local command = words[1]

	-- For lines where there are two words, the first being the key and the second being a string that is the value
	if command == "save_name" or command == "data_name" or command == "test_name" then

		config_table[command] = words[2]

	end

	-- For single value that is a number
	if command == "gpu_id" or command == "output_level" then

		config_table[command] = tonumber(words[2])

	end

end

--print("Configuration")
--print(config_table)

-- The name to save this model as
--save_name = 'fcn_32_easy'
save_name = config_table["save_name"]

-- Where to load data from
--data_name = "/media/6a2ce75c-12d0-4cf5-beaa-875c0cd8e5d8/Easy_set_01_threshold.hdf5"
data_name = config_table["data_name"]

-- Test data
--test_name = "/media/6a2ce75c-12d0-4cf5-beaa-875c0cd8e5d8/Easy_set_01_test.hdf5"
test_name = config_table["test_name"]

-- GPU device number to use
gpu_id = config_table["gpu_id"] or 1

-- Level of output
output_level = config_table["output_level"] or 2

-- Sets if images will be noised for training
use_noise = true
sigma = .1

-- Network size configurations
-- TODO: make these automatic
-- The number of output classes
n_classes = 13

-- The size of the images being processed
height = 480
width = 640

-- Enumeration of the classes
classes = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '12'}

-- Set the default tensor type for cpu use
torch.setdefaulttensortype("torch.FloatTensor")

-- Set the gpu to run the whole system on
print("Using GPU: " .. gpu_id)
cutorch.setDevice(gpu_id)

-- Training function
function train(checkpoint)

	-- Make sure the model is in training mode
	model:training()

	-- How often the network will stop for testing and saving
	-- Set to negative for no checkpoints
	local checkpoint = checkpoint or 5000

	local save_name = save_name or 'fcn_32'

	-- The amount of images to check at each checkpoint

	-- For counting the data items
	local count = 0

	-- For tracking the loss of the network
	local current_loss = 0

	-- Get the shape of the data set
	local data_shape = data_set:dataspaceSize()
	local n_images = data_shape[1]
	local height = data_shape[2]
	local width = data_shape[3]

	-- Go through each image one at a time
	for i = 1, n_images - 1 do

		io.write("\rWorking on image " .. i)
		--io.flush()

		collectgarbage()

		-- Load the data item
		local data_item = data_set:partial({i,i},{1,height},{1,width}):cuda()

		-- load the label

		local label_item = label_set:partial({i,i}, {1,height}, {1,width}):squeeze():cuda()

		label_item = label_item:view(label_item:nElement()) + 1

		-- Closure for feval to get gradients
		local feval = function(x_new)

			-- Set the bias of the upscale layer to zero
			-- Assuming that model is on GPU
			-- TODO make a layer that has no bias
			model:get(upscale_layer_index).bias = torch.CudaTensor(n_classes):fill(0)
			model:get(upscale_layer_index - 1).bias = torch.CudaTensor(n_classes):fill(0)

			-- Reset the data
			if x~= x_new then x:copy(x_new) end
			dl_dx:zero()

			-- Run the forward input
			local output = model:forward(data_item)

			-- Gradient descent for the image
			local loss = criterion:forward(model.output, label_item)
			model:backward(data_item, criterion:backward(model.output, label_item))

			return loss, dl_dx
		end

		_, fs = optim.sgd(feval, x, sgd_params)

		io.write(" loss " .. fs[1] .. "                ")
		io.flush()

		count = count + 1

		current_loss = current_loss + fs[1]

		-- At checkpoints, do a temp save and test the model
		if checkpoint > 0 and i % checkpoint == 0 then

			if output_level >= 2 then

				test(3)
				model:training()

			end

			-- Save the model on the cpu, to prevent issues when loading
			--model:float()
			torch.save(save_name .. '_temp.dat', model)
			--model:cuda()

		end

	end

	io.write("\n")

	return current_loss / count

end

-- Test function
-- Send -1 to reset a previous call to test and use bounds of the data set
function test(stop, start)

	print("")
	print("Testing")

	if not start or start == -1 then

		start = 1

	end

	if not stop or stop == -1 then

		stop = test_set:dataspaceSize()[1]

	end

	-- The confusion matrix
	local confusion = optim.ConfusionMatrix({"Non-person", "Head_L", "Head_R", "Torso_L", "Torso_R", "Upper_arm_L", "Upper_arm_R", "Lower_arm_L", "Lower_arm_R", "Upper_leg_L", "Upper_leg_R", "Lower_leg_L", "Lower_Leg_R"})

	-- Total number of images being tested
	local test_im_total = test_set:dataspaceSize()[1]

	-- Set to evaluate to get production mode
	model:evaluate()

	-- Go through each image in the test set
	for i = start, stop do

		-- Progress bar
		--xlua.progress(i, test_im_total)
		io.write("\rWorking on image " .. i .. " of " .. stop - start + 1)
		io.flush()

		-- Get an image
		local data_item = test_set:partial({i,i},{1,height},{1,width}):cuda()

		-- load the label
		local label_item = test_label_set:partial({i,i}, {1,height}, {1,width}):squeeze():cuda()
		label_item = label_item:view(label_item:nElement()) + 1

		-- Get the forward prediction of the log probabilities
		local prediction_log_probs = model:forward(data_item)

		-- Get the class of each pixel
		local ignore, predictions = torch.max(prediction_log_probs, 2)
		predictions = predictions:squeeze():type('torch.FloatTensor')
		label_item = label_item:type('torch.FloatTensor')

		-- Add to the confusion matrix
		confusion:batchAdd(predictions, label_item)

	end

	-- Show the confusion matrix
	print("")
	print(confusion)

	return confusion

end

-- Saves example images from the test set as hdf5 files
function save_image_examples(ex_stop, ex_start)

	print("")
	print("Getting test images")

	if not ex_start or ex_start == -1 then

		ex_start = 1

	end

	if not ex_stop or ex_stop == -1 then

		ex_stop = test_set:dataspaceSize()[1]

	end

	-- hdf5 save file
	local hdf5_file = hdf5.open(save_name .. "_ex_ims.hdf5", 'w')

	-- Set to evaluate to get production mode
	model:evaluate()

	-- Make a tensor with the shape (n_images, height, width)
	local ex_images = torch.Tensor(stop - start, height, width)

	-- Go through each image in the test set
	local count = 1
	for i = ex_start, ex_stop do

		-- Progress bar
		--xlua.progress(i, test_im_total)
		io.write("\rWorking on image " .. i .. " of " .. stop - start + 1)

		-- Get an image
		local data_item = test_set:partial({i,i},{1,height},{1,width}):cuda()

		-- load the label
		local label_item = test_label_set:partial({i,i}, {1,height}, {1,width}):squeeze():cuda()
		label_item = label_item:view(label_item:nElement()) + 1

		-- Get the forward prediction of the log probabilities
		local prediction_log_probs = model:forward(data_item)

		-- Get the class of each pixel
		local ignore, predictions = torch.max(prediction_log_probs, 2)
		predictions = predictions:squeeze():type('torch.FloatTensor')
		label_item = label_item:type('torch.FloatTensor')

		-- Set the correct index in the output tensor
		ex_images[count] = label_item

		count = count + 1

	end

	-- Write the tensor to the file
	hdf5_file:write('batch', ex_images)

	-- Close the file
	hdf5_file:close()

end

print("Loading data from:")
print(data_name)

-- Get the handle for the whole data set
whole_set = hdf5.open(data_name, 'r')

-- Get the handles for the data and label sets
data_set = whole_set:read('data')
label_set = whole_set:read('label')

print("Data shape:")
print(data_set:dataspaceSize())

print("Label shape:")
print(label_set:dataspaceSize())

print("Loading test set from:")
print(test_name)

-- Open the test set
whole_test_set = hdf5.open(test_name, 'r')

-- Get the handles for the test data and labels
test_set = whole_test_set:read('data')
test_label_set = whole_test_set:read('label')

print("Creating the model")
-- The last main line convolution and pooling
-- Starts from pool4
final_main = nn.Sequential()

-- Tracks the amount of sampling
sampling = 1

-- The kernel size to use for all standard conv layers
k_size = 3

-- The padding needed on standard conv layers to keep shape right
pad = torch.floor((k_size - 1)/2)

-- conv1
--conv1_planes = 64
conv1_planes = 32

final_main:add(nn.SpatialConvolution(1, conv1_planes, k_size, k_size, 1, 1, pad, pad)) -- conv1_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv1_planes, conv1_planes, k_size, k_size, 1, 1, pad, pad)) -- conv1_2
final_main:add(nn.ReLU())

-- pool1
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv2
--conv2_planes = 128
conv2_planes = 64

final_main:add(nn.SpatialConvolution(conv1_planes, conv2_planes, k_size, k_size, 1, 1, pad, pad)) -- conv2_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv2_planes, conv2_planes, k_size, k_size, 1, 1, pad, pad)) -- conv2_2
final_main:add(nn.ReLU())

-- pool2
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv3
--conv3_planes = 256
conv3_planes = 128

final_main:add(nn.SpatialConvolution(conv2_planes, conv3_planes, k_size, k_size, 1, 1, pad, pad)) -- conv3_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv3_planes, conv3_planes, k_size, k_size, 1, 1, pad, pad)) -- conv3_2
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv3_planes, conv3_planes, k_size, k_size, 1, 1, pad, pad)) -- conv3_3
final_main:add(nn.ReLU())

-- pool3
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv4
--conv4_planes = 512
conv4_planes = 256

final_main:add(nn.SpatialConvolution(conv3_planes, conv4_planes, k_size, k_size, 1, 1, pad, pad)) -- conv4_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv4_planes, conv4_planes, k_size, k_size, 1, 1, pad, pad)) -- conv4_2
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv4_planes, conv4_planes, k_size, k_size, 1, 1, pad, pad)) -- conv4_3
final_main:add(nn.ReLU())

-- pool4
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv5
--conv5_planes = 512
conv5_planes = 256

final_main:add(nn.SpatialConvolution(conv4_planes, conv5_planes, k_size, k_size, 1, 1, pad, pad)) -- conv5_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv5_planes, conv5_planes, k_size, k_size, 1, 1, pad, pad)) -- conv5_2
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv5_planes, conv5_planes, k_size, k_size, 1, 1, pad, pad)) -- conv5_3

-- pool5
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv6-7
-- aka fc6-7
--fc6_7_planes = 4096 --Amount in paper, but uses too much memory
--fc6_7_planes = 3072
--fc6_7_planes = 1024 -- Works on GTX 960
fc6_7_planes = 1024

final_main:add(nn.SpatialConvolution(conv5_planes, fc6_7_planes, 7, 7, 1, 1, 3, 3)) -- fc6
final_main:add(nn.ReLU())
final_main:add(nn.Dropout(.5))
final_main:add(nn.SpatialConvolution(fc6_7_planes, fc6_7_planes, 1, 1)) -- fc7
final_main:add(nn.ReLU())
final_main:add(nn.Dropout(.5))

-- output layer
final_main:add(nn.SpatialConvolution(fc6_7_planes, n_classes, 1, 1))

-- Upscale all of the previous downsamplings
final_main:add(nn.SpatialFullConvolution(n_classes, n_classes, 2*sampling, 2*sampling, sampling, sampling, sampling/2, sampling/2))

-- Set the layer where the upscaling occurs, so that the bias can be removed
upscale_layer_index = 38

-- Reorder and reshape from (n_classes, height, width) to (height * width, n_classes)
final_main:add(nn.StackShift())

-- For using ClassNLL
-- Needs LogSoftMax layer
-- Needs to be reshaped to width * height, n_classes
final_main:add(nn.LogSoftMax())

-- Put the model together
-- Nothing to do for this right now
model = final_main

-- Move to GPU
model:cuda()

print("Constructed model:")
print(model)

-- Using Negative Log Likelihood
criterion = nn.ClassNLLCriterion():cuda()

-- Parameters for SGD

-- Very slow
--[[
sgd_params = {
	learningRate = 1e-2,
	learningRateDecay = 1e-4,
	weightDecay = 1e-3,
	momentum = 1e-4
}
--]]

-- Aggressive, but not very accurate
--[[
sgd_params = {
	learningRate = .5,
	learningRateDecay = 1e-4,
	weightDecay = 1e-3,
	momentum = .9
}
--]]

-- Good middle ground, high initial learning rate that decays quickly
sgd_params = {
	learningRate = .1,
	learningRateDecay = .001,
	weightDecay = .0001,
	momentum = .5
}

print("Using SGD parameters:")
print(sgd_params)

-- TODO what is this exactly
x, dl_dx = model:getParameters()

-- Run for the specified number of epochs
max_epochs = 10
for epoch = 1, max_epochs do

	-- Time the epoch
	timer = torch.Timer()

	-- Do the training
	this_loss = train()

	-- Get the end time
	end_time = timer:time().real

	print("Loss at epoch " .. epoch .. ": " .. this_loss)
	print("Time taken: " .. end_time)

	-- Do a test
	test()

end

print("Training complete")
--print("Average time taken for training an epoch: " .. end_time / max_epochs)
--print("Total time: " .. end_time)

-- Save the completed model on the cpu to avoid loading issues
model:float()
torch.save(save_name .. '.dat', model)
model:cuda()

-- Close the hdf5
whole_set:close()
whole_test_set:close()
