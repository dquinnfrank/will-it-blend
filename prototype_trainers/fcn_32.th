require 'torch'
require 'cutorch'
require 'cunn'
require 'optim'
require 'xlua'

require 'hdf5'

--require 'StackShift'

-- Implementing: https://gist.github.com/shelhamer/80667189b218ad570e82#file-readme-md

-- Network size configurations
-- TODO: make these automatic
-- The number of output classes
n_classes = 13

-- The size of the images being processed
height = 480
width = 640

-- Enumeration of the classes
classes = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '12'}

-- Set the default tensor type for cpu use
torch.setdefaulttensortype("torch.FloatTensor")

-- Training function
function train()

	-- How often the network will stop for testing and saving
	-- Set to negative for no checkpoints
	checkpoint = 1000

	-- For counting the data items
	local count = 0

	-- For tracking the loss of the network
	current_loss = 0

	-- Get the shape of the data set
	data_shape = data_set:dataspaceSize()
	n_images = data_shape[1]
	height = data_shape[2]
	width = data_shape[3]

	-- Go through each image one at a time
	for i = 1, n_images - 1 do

		io.write("\rWorking on image " .. i)

		collectgarbage()

		-- Load the data item
		local data_item = data_set:partial({i,i},{1,height},{1,width}):cuda()
		--local data_item = data_set:partial({i,i},{1,height},{1,width})

		-- load the label
		--local label_item = label_set:partial({i,i}, {1,height}, {1,width}, {1,n_classes}):cuda()
		local label_item = label_set:partial({i,i}, {1,height}, {1,width}):squeeze():cuda()
		--local label_item = label_item:view(label_item:nElement())
		--label_item = label_set:partial({i,i}, {1,height}, {1,width}):squeeze()

		label_item = label_item:view(label_item:nElement()) + 1

		-- Closure for feval to get gradients
		local feval = function(x_new)

			-- Reset the data
			if x~= x_new then x:copy(x_new) end
			dl_dx:zero()

			-- Run the forward input
			output = model:forward(data_item)

			-- Gradient descent for the image
			local loss = criterion:forward(model.output, label_item)
			model:backward(data_item, criterion:backward(model.output, label_item))

			return loss, dl_dx
		end

		_, fs = optim.sgd(feval, x, sgd_params)

		io.write(" loss " .. fs[1])
		io.flush()

		count = count + 1

		current_loss = current_loss + fs[1]

		-- At checkpoints, do a temp save and test the model
		if checkpoint > 0 and i % checkpoint == 0 then

			test(3)
			model:training()

			torch.save('temp.dat', model)

		end

	end

	io.write("\n")

	return current_loss / count

end

-- Test function
-- Send -1 to reset a previous call to test and use bounds of the data set
function test(stop, start)

	print("")
	print("Testing")

	if not start or start == -1 then

		start = 1

	end

	if not stop or stop == -1 then

		stop = test_set:dataspaceSize()[1]

	end

	-- The confusion matrix
	--local confusion = optim.ConfusionMatrix(13)
	local confusion = optim.ConfusionMatrix({"Non-person", "Head_L", "Head_R", "Torso_L", "Torso_R", "Upper_arm_L", "Upper_arm_R", "Lower_arm_L", "Lower_arm_R", "Upper_leg_L", "Upper_leg_R", "Lower_leg_L", "Lower_Leg_R"})

	-- Total number of images being tested
	local test_im_total = test_set:dataspaceSize()[1]

	-- Set to evaluate to get production mode
	model:evaluate()

	-- Go through each image in the test set
	for i = start, stop do

		-- Progress bar
		--xlua.progress(i, test_im_total)
		io.write("\rWorking on image " .. i .. " of " .. stop - start + 1)

		-- Get an image
		local data_item = test_set:partial({i,i},{1,height},{1,width}):cuda()

		-- load the vector label
		local label_item = test_label_set:partial({i,i}, {1,height}, {1,width}):squeeze():cuda()
		label_item = label_item:view(label_item:nElement()) + 1

		-- Get the forward prediction of the log probabilities
		local prediction_log_probs = model:forward(data_item)

		-- Get the class of each pixel
		local ignore, predictions = torch.max(prediction_log_probs, 2)
		predictions = predictions:squeeze():type('torch.FloatTensor')
		label_item = label_item:type('torch.FloatTensor')

		-- Add to the confusion matrix
		confusion:batchAdd(predictions, label_item)

	end

	-- Show the confusion matrix
	print("")
	print(confusion)

	-- Show the biases of the Deconvolution layer
	print("Bias of upscaling layer")
	print(model:get(38).bias)

end

-- Where to load data from
--load_set = "/media/ebcf6e76-2430-41c9-917a-d331f6258c57/occulsion_data/Easy_set_01.hdf5"
--load_set = "/home/master/will-it-blend/generated_data/vect_test.hdf5"
--load_set = "/media/6a2ce75c-12d0-4cf5-beaa-875c0cd8e5d8/occulsion_data/Easy_set_01_no_vect_test.hdf5"

load_set = "/media/6a2ce75c-12d0-4cf5-beaa-875c0cd8e5d8/Easy_set_01_threshold.hdf5"

print("Loading data from:")
print(load_set)

-- Get the handle for the whole data set
whole_set = hdf5.open(load_set, 'r')

-- Get the handles for the data and label sets
data_set = whole_set:read('data')
label_set = whole_set:read('label')

print("Data shape:")
print(data_set:dataspaceSize())

print("Label shape:")
print(label_set:dataspaceSize())

-- Test data
test_name = "/media/6a2ce75c-12d0-4cf5-beaa-875c0cd8e5d8/Easy_set_01_test.hdf5"

print("Loading test set from:")
print(test_name)

-- Open the test set
whole_test_set = hdf5.open(test_name, 'r')

-- Get the handles for the test data and labels
test_set = whole_test_set:read('data')
test_label_set = whole_test_set:read('label')

-- Set the GPU to use
cutorch.setDevice(1)

print("Creating the model")
-- The last main line convolution and pooling
-- Starts from pool4
final_main = nn.Sequential()

-- Tracks the amount of sampling
sampling = 1

-- The kernel size to use for all standard conv layers
k_size = 3

-- The padding needed on standard conv layers to keep shape right
pad = torch.floor((k_size - 1)/2)

-- conv1
--conv1_planes = 64
conv1_planes = 32

final_main:add(nn.SpatialConvolution(1, conv1_planes, k_size, k_size, 1, 1, pad, pad)) -- conv1_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv1_planes, conv1_planes, k_size, k_size, 1, 1, pad, pad)) -- conv1_2
final_main:add(nn.ReLU())

-- pool1
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv2
--conv2_planes = 128
conv2_planes = 64

final_main:add(nn.SpatialConvolution(conv1_planes, conv2_planes, k_size, k_size, 1, 1, pad, pad)) -- conv2_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv2_planes, conv2_planes, k_size, k_size, 1, 1, pad, pad)) -- conv2_2
final_main:add(nn.ReLU())

-- pool2
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv3
--conv3_planes = 256
conv3_planes = 128

final_main:add(nn.SpatialConvolution(conv2_planes, conv3_planes, k_size, k_size, 1, 1, pad, pad)) -- conv3_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv3_planes, conv3_planes, k_size, k_size, 1, 1, pad, pad)) -- conv3_2
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv3_planes, conv3_planes, k_size, k_size, 1, 1, pad, pad)) -- conv3_3
final_main:add(nn.ReLU())

-- pool3
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv4
--conv4_planes = 512
conv4_planes = 256

final_main:add(nn.SpatialConvolution(conv3_planes, conv4_planes, k_size, k_size, 1, 1, pad, pad)) -- conv4_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv4_planes, conv4_planes, k_size, k_size, 1, 1, pad, pad)) -- conv4_2
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv4_planes, conv4_planes, k_size, k_size, 1, 1, pad, pad)) -- conv4_3
final_main:add(nn.ReLU())

-- pool4
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv5
--conv5_planes = 512
conv5_planes = 256

final_main:add(nn.SpatialConvolution(conv4_planes, conv5_planes, k_size, k_size, 1, 1, pad, pad)) -- conv5_1
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv5_planes, conv5_planes, k_size, k_size, 1, 1, pad, pad)) -- conv5_2
final_main:add(nn.ReLU())
final_main:add(nn.SpatialConvolution(conv5_planes, conv5_planes, k_size, k_size, 1, 1, pad, pad)) -- conv5_3

-- pool5
sampling = 2 * sampling
final_main:add(nn.SpatialMaxPooling(2, 2, 2, 2))

-- conv6-7
-- aka fc6-7
--fc6_7_planes = 4096 --Amount in paper, but uses too much memory
--fc6_7_planes = 3072
--fc6_7_planes = 1024 -- Works on GTX 960
fc6_7_planes = 1024

final_main:add(nn.SpatialConvolution(conv5_planes, fc6_7_planes, 7, 7, 1, 1, 3, 3)) -- fc6
final_main:add(nn.ReLU())
final_main:add(nn.Dropout(.5))
final_main:add(nn.SpatialConvolution(fc6_7_planes, fc6_7_planes, 1, 1)) -- fc7
final_main:add(nn.ReLU())
final_main:add(nn.Dropout(.5))

-- output layer
final_main:add(nn.SpatialConvolution(fc6_7_planes, n_classes, 1, 1))

-- Upscale all of the previous downsamplings
--final_main:add(nn.SpatialUpSamplingNearest(sampling))
final_main:add(nn.SpatialFullConvolution(n_classes, n_classes, 2*sampling, 2*sampling, sampling, sampling, sampling/2, sampling/2))

final_main:add(nn.Reshape(height * width, n_classes))

-- For using ClassNLL
-- Needs LogSoftMax layer
-- Needs to be reshaped to width * height, n_classes
-- WARNING: the network is only suitable for running one image at a time because of this
final_main:add(nn.LogSoftMax())

-- Put the model together
-- Nothing to do for this right now
model = final_main

-- Move to GPU
model:cuda()

print("Constructed model:")
print(model)
--os.execute("sleep " .. 10)

-- Using Negative Log Likelihood
criterion = nn.ClassNLLCriterion():cuda()

-- Parameters for SGD

sgd_params = {
	learningRate = 1e-2,
	learningRateDecay = 1e-4,
	weightDecay = 1e-3,
	momentum = 1e-4
}

--[[
sgd_params = {
	learningRate = .5,
	learningRateDecay = 1e-4,
	weightDecay = 1e-3,
	momentum = .9
}
--]]

-- TODO what is this exactly
x, dl_dx = model:getParameters()

-- Time the training
timer = torch.Timer()

-- Run for the specified number of epochs
max_epochs = 10
for epoch = 1, max_epochs do

	-- Do the training
	this_loss = train()

	print("Loss at epoch " .. epoch .. ": " .. this_loss)

	-- Do a test
	test()
	model:training()

end

-- Get the end time
end_time = timer:time().real

print("Training complete")
print("Average time taken for training an epoch: " .. end_time / max_epochs)
print("Total time: " .. end_time)

-- Save the completed model
torch.save('test_model.dat', model)

-- Close the hdf5
whole_set:close()
whole_test_set:close()
